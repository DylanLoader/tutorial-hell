{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, recall_score, average_precision_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, recall_score, average_precision_score, precision_score\n",
    "\n",
    "def generate_date_features(transactions_df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Generates features from the creation date of a transaction\n",
    "\n",
    "    Args:\n",
    "        transactions_df (pd.DataFrame): The transaction dataframe\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The transaction dataframe with the new features\n",
    "    \"\"\"\n",
    "    transactions_df['time_bin'] = pd.qcut((transactions_df['CREATED_DATE'].dt.hour * 60 + transactions_df['CREATED_DATE'].dt.minute) * 60 + transactions_df['CREATED_DATE'].dt.minute, 20, labels=range(20)).astype('int')\n",
    "    transactions_df['hour'] = transactions_df['CREATED_DATE'].dt.hour\n",
    "    transactions_df['minute'  ] = transactions_df['CREATED_DATE'].dt.minute\n",
    "    transactions_df['week'] = transactions_df['CREATED_DATE'].dt.isocalendar().week\n",
    "    transactions_df['weekday'] = transactions_df['CREATED_DATE'].dt.weekday\n",
    "    transactions_df['dayofyear'] = transactions_df['CREATED_DATE'].dt.dayofyear\n",
    "    transactions_df['dayofyear_hour_bin'] = pd.qcut((transactions_df['dayofyear'] * transactions_df['hour']).rank(method='first'), 20, labels=range(20)).astype('int')\n",
    "    transactions_df['weekday_hour'] = transactions_df['weekday'] * transactions_df['hour']\n",
    "    \n",
    "    return transactions_df\n",
    "\n",
    "def draw_features(transactions:pd.DataFrame, use_features:list) -> None:\n",
    "    \"\"\"Produces a factor plot of every feature used where the percentage for each feature is\n",
    "\n",
    "    Args:\n",
    "        transactions (pd.DataFrame): _description_\n",
    "        use_features (list): _description_\n",
    "    \"\"\"\n",
    "    for feat in use_features:\n",
    "        agg = transactions.groupby(['is_fraud', feat]).agg({'ID': 'count'})\n",
    "        df = agg.groupby(level=0).apply(lambda x: x / float(x.sum())).reset_index()\n",
    "        plt.figure(figsize=(14,10))\n",
    "        ax = sns.factorplot(x=feat, y='ID', hue='is_fraud', data=df, kind='bar', size=6, aspect=2)\n",
    "        ax.fig.suptitle(feat.upper()+' by is_fraud - % of transactions')\n",
    "        ax.set_xticklabels(rotation=20)\n",
    "        plt.show()\n",
    "\n",
    "def model_metrics(y_v: list, y_t:list, score:list) -> pd.Series:\n",
    "    leng = int(y_v.index.nunique()+y_t.index.nunique())\n",
    "    targ_m = np.mean(y_v[y_v==1].index.nunique() / y_v.index.nunique())\n",
    "    targ_q = leng * targ_m\n",
    "    gini = np.round(2*roc_auc_score(y_v, score)-1, 4)\n",
    "    auc = np.round(roc_auc_score(y_v, score), 4)\n",
    "    aucpr = np.round(average_precision_score(y_v, score), 4)\n",
    "    return pd.Series([leng, targ_m, targ_q, gini, auc, aucpr], index=[\"Length\", \"Target Mean\", \"Targets\", \"Gini\", \"AUC\", \"AUCPR\"])\n",
    "\n",
    "def model_metrics_cut(y_v: list, y_t:list, score:list, cutoff) -> pd.Series:\n",
    "    \n",
    "    pred = np.sum((score>cutoff).astype(int))\n",
    "    prec = precision_score(y_v, (score>cutoff).astype(int))\n",
    "    rec = recall_score(y_v, (score>cutoff).astype(int))\n",
    "    corr = prec * pred\n",
    "    incorr = pred-corr\n",
    "    lift = prec/np.mean(y_v)\n",
    "    lift = np.round(lift, 4)\n",
    "    prec = np.round(prec,4)\n",
    "    rec = np.round(rec, 4)\n",
    "    extr = np.round(y_t.index.nunique()/y_v.index.nunique()+1)\n",
    "    pred = np.round(pred*extr)\n",
    "    corr = np.round(corr*extr)\n",
    "    incorr = np.round(incorr*extr)\n",
    "    rev_tp = corr * revenue_tp\n",
    "    cost_ul_fp = incorr * cost_unlock_fp\n",
    "    cost_ch_fp = incorr * cost_check_fp\n",
    "    return pd.Series([cutoff, pred,corr, incorr, prec,rec, lift, rev_tp, cost_ul_fp, cost_ch_fp], \n",
    "                     index=['Cutoff','Predicted', 'Correct', 'Incorrect', 'Precision', 'Recall','Lift', 'Revenue_Correct', 'Cost_Unlock_Incorrect', 'Cost_Check_Incorrect'])\n",
    "    \n",
    "def calc_profit(mod_metr_cut_df:pd.DataFrame, i:int, j:int)-> float:\n",
    "    rev_tp = mod_metr_cut_df['Revenue_Correct'][j] - (mod_metr_cut_df['Correct'][j] - mod_metr_cut_df['Correct'][i]) * cost_check_fp\n",
    "    cost_ul_fp = mod_metr_cut_df['Cost_Unlock_Incorrect'][i]\n",
    "    cost_ch_fp = mod_metr_cut_df['Cost_Check_Incorrect'][j]-mod_metr_cut_df['Cost_Check_Incorrect'][i]\n",
    "    profit = (rev_tp - cost_ul_fp - cost_ch_fp) \n",
    "    return profit\n",
    "\n",
    "def maximize_profit(mod_metr_cut_df:pd.DataFrame, cutoff:list):\n",
    "    max_profit = 0 \n",
    "    best_lock = 0\n",
    "    best_check = 0\n",
    "\n",
    "    for i in tqdm(range(len(cutoff)-1)):\n",
    "      for j in range(i + 1, len(cutoff)-2):\n",
    "        profit = calc_profit(mod_metr_cut_df, i, j)\n",
    "        if (profit) > max_profit:\n",
    "            max_profit = profit\n",
    "            best_lock = i\n",
    "            best_check = j\n",
    "            score_lock = mod_metr_cut_df['Cutoff'][i]\n",
    "            score_check = mod_metr_cut_df['Cutoff'][j]\n",
    "    return max_profit, score_lock, score_check, best_lock, best_check\n",
    "  \n",
    "def display_importances_xgb(model, use_features:list)-> None:\n",
    "    fmap = {'f'+ str(index): x for index, x in enumerate(use_features, start=0)}\n",
    "    fimp_df = pd.DataFrame(list(model.get_booster().get_fscore().items()))\n",
    "    fimp_df.columns = ['feature', 'importance']\n",
    "    fimp_df['importance']=fimp_df['importance']/np.sum(fimp_df['importance'])\n",
    "    fimp_df['feature'] = fimp_df['feature'].map(fmap)\n",
    "\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=fimp_df.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('Feature Importance')\n",
    "    plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine variables and definitions\n",
    "parse_dates = ['CREATED_DATE']\n",
    "users_df = pd.read_csv(\"../data/revolut/users.csv\", parse_dates=parse_dates)\n",
    "fraudsters_df = pd.read_csv(\"../data/revolut/fraudsters.csv\")\n",
    "transactions_df = pd.read_csv(\"../data/revolut/transactions.csv\", parse_dates=parse_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>CREATED_DATE</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>AMOUNT_GBP</th>\n",
       "      <th>CURRENCY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f659b44e-cfdf-48de-bcf3-06f47ef26e9f</td>\n",
       "      <td>fd7f3ff6-0ed6-4a85-a7b5-2f205e0ef72f</td>\n",
       "      <td>2019-04-20 18:04:03.930</td>\n",
       "      <td>CARD_PAYMENT</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>13.12</td>\n",
       "      <td>PLN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2ae18b8b-b9bc-4c44-96b1-d43efd8d371d</td>\n",
       "      <td>3979518e-95f7-4b6c-81ae-2f828727d81a</td>\n",
       "      <td>2019-05-03 13:09:57.625</td>\n",
       "      <td>TOPUP</td>\n",
       "      <td>REVERTED</td>\n",
       "      <td>0.01</td>\n",
       "      <td>RON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0162d352-dd18-40ab-b3ee-cf6584c9a238</td>\n",
       "      <td>75aa5388-9c89-4f72-bc54-67501519585b</td>\n",
       "      <td>2019-04-25 15:37:46.837</td>\n",
       "      <td>TOPUP</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>10.00</td>\n",
       "      <td>GBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a4e176f7-49ca-462b-9164-2f0645622148</td>\n",
       "      <td>45598164-6362-4ee4-bd70-ffee3bd1d707</td>\n",
       "      <td>2019-04-28 13:52:15.256</td>\n",
       "      <td>EXCHANGE</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>0.11</td>\n",
       "      <td>RON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f6f9135f-fb2b-4a58-bb65-dd9713306a71</td>\n",
       "      <td>5a501ce5-f03c-410d-aabc-434b2cad741d</td>\n",
       "      <td>2019-05-13 16:02:12.081</td>\n",
       "      <td>CARD_PAYMENT</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>9.79</td>\n",
       "      <td>EUR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID                               USER_ID  \\\n",
       "0  f659b44e-cfdf-48de-bcf3-06f47ef26e9f  fd7f3ff6-0ed6-4a85-a7b5-2f205e0ef72f   \n",
       "1  2ae18b8b-b9bc-4c44-96b1-d43efd8d371d  3979518e-95f7-4b6c-81ae-2f828727d81a   \n",
       "2  0162d352-dd18-40ab-b3ee-cf6584c9a238  75aa5388-9c89-4f72-bc54-67501519585b   \n",
       "3  a4e176f7-49ca-462b-9164-2f0645622148  45598164-6362-4ee4-bd70-ffee3bd1d707   \n",
       "4  f6f9135f-fb2b-4a58-bb65-dd9713306a71  5a501ce5-f03c-410d-aabc-434b2cad741d   \n",
       "\n",
       "             CREATED_DATE          TYPE      STATE  AMOUNT_GBP CURRENCY  \n",
       "0 2019-04-20 18:04:03.930  CARD_PAYMENT  COMPLETED       13.12      PLN  \n",
       "1 2019-05-03 13:09:57.625         TOPUP   REVERTED        0.01      RON  \n",
       "2 2019-04-25 15:37:46.837         TOPUP  COMPLETED       10.00      GBP  \n",
       "3 2019-04-28 13:52:15.256      EXCHANGE  COMPLETED        0.11      RON  \n",
       "4 2019-05-13 16:02:12.081  CARD_PAYMENT  COMPLETED        9.79      EUR  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CREATED_DATE</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46f44852-aaa5-4634-aadd-8cc4eefef3c8</td>\n",
       "      <td>2019-04-22 18:30:30.735</td>\n",
       "      <td>BG</td>\n",
       "      <td>1984-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f17dd8af-2edb-4415-a950-d90a1b5e3e5b</td>\n",
       "      <td>2019-04-15 02:44:24.940</td>\n",
       "      <td>IE</td>\n",
       "      <td>1984-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55e6fcef-f573-4c54-8b27-537adc417e19</td>\n",
       "      <td>2019-04-03 16:10:44.530</td>\n",
       "      <td>PL</td>\n",
       "      <td>1977-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dc03019c-9cf1-4081-a70a-6922a44fe393</td>\n",
       "      <td>2019-04-13 14:16:11.928</td>\n",
       "      <td>FR</td>\n",
       "      <td>1992-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bcd967e5-c273-45a7-a7f5-e7c9e3b19b7e</td>\n",
       "      <td>2019-04-03 15:46:43.997</td>\n",
       "      <td>IE</td>\n",
       "      <td>1993-10-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID            CREATED_DATE COUNTRY  \\\n",
       "0  46f44852-aaa5-4634-aadd-8cc4eefef3c8 2019-04-22 18:30:30.735      BG   \n",
       "1  f17dd8af-2edb-4415-a950-d90a1b5e3e5b 2019-04-15 02:44:24.940      IE   \n",
       "2  55e6fcef-f573-4c54-8b27-537adc417e19 2019-04-03 16:10:44.530      PL   \n",
       "3  dc03019c-9cf1-4081-a70a-6922a44fe393 2019-04-13 14:16:11.928      FR   \n",
       "4  bcd967e5-c273-45a7-a7f5-e7c9e3b19b7e 2019-04-03 15:46:43.997      IE   \n",
       "\n",
       "   BIRTH_DATE  \n",
       "0  1984-10-22  \n",
       "1  1984-11-04  \n",
       "2  1977-09-08  \n",
       "3  1992-09-06  \n",
       "4  1993-10-22  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2c831c76-2d62-41ce-a240-e12f505d389a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ce2a1146-831e-49a7-aa5f-a3045a2892af</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>447abe11-f89a-4819-bea2-e7978b1cf560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3a186446-c2fb-474b-a8d8-db362643b3d2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73fa6100-f6f0-4e22-b247-714f4743c125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                USER_ID\n",
       "0  2c831c76-2d62-41ce-a240-e12f505d389a\n",
       "1  ce2a1146-831e-49a7-aa5f-a3045a2892af\n",
       "2  447abe11-f89a-4819-bea2-e7978b1cf560\n",
       "3  3a186446-c2fb-474b-a8d8-db362643b3d2\n",
       "4  73fa6100-f6f0-4e22-b247-714f4743c125"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraudsters_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset merging\n",
    "users_df = users_df.rename({'ID':'USER_ID', 'CREATED_DATE':'USER_CREATED_DATE'}, axis='columns')\n",
    "transactions_df = pd.merge(transactions_df, users_df, on=['USER_ID'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the fraud labels\n",
    "transactions_df['is_fraud'] = transactions_df['USER_ID'].isin(fraudsters_df['USER_ID'].unique()).astype(int)\n",
    "# Get the first digit of the transaction amount to check distribution under Benford's Law\n",
    "transactions_df['first_digit'] = transactions_df['AMOUNT_GBP'].astype('str').str[0].astype('int')\n",
    "# Also get the last digit incase transactions are structured in a way to commit fraud.\n",
    "transactions_df['last_digit'] = transactions_df['AMOUNT_GBP'].astype('str').str[-1].astype('int')\n",
    "# Get the number of times each user has topped up their account \n",
    "transactions_df['user_cnt_topups'] = transactions_df['USER_ID'].map(transactions_df[transactions_df['TYPE']=='TOPUP'].groupby('USER_ID')['ID'].count())\n",
    "# Get the mean amount of each topup\n",
    "transactions_df['user_mean_topups'] = pd.qcut(transactions_df['USER_ID'].map(transactions_df[transactions_df['TYPE']=='TOPUP'].groupby('USER_ID')['AMOUNT_GBP'].mean()), 15, labels=range(15)).astype(int)\n",
    "transactions_df['user_std_topups'] = pd.qcut(transactions_df['USER_ID'].map(transactions_df[transactions_df['TYPE']=='TOPUP'].groupby('USER_ID')['AMOUNT_GBP'].std().fillna(0)), 15, labels=range(15)).astype(int)\n",
    "\n",
    "# Get the number of unique states in which the user interacts. \n",
    "transactions_df['user_uniq_states'] = transactions_df['USER_ID'].map(transactions_df[transactions_df['TYPE']=='TOPUP'].groupby('USER_ID')['STATE'].nunique())\n",
    "# Create interger mapping for each unique country\n",
    "transactions_df['country'] = pd.factorize(transactions_df['COUNTRY'])[0]\n",
    "tmp = transactions_df.groupby(['USER_ID']).agg({'CREATED_DATE': [np.min, np.max], 'ID': 'count'}).reset_index()\n",
    "tmp.columns = ['USER_ID', 'MIN_DATE', 'MAX_DATE', 'COUNT']\n",
    "tmp['mean_time_to_tran_min'] = (np.round((((tmp['MAX_DATE']-tmp['MIN_DATE']).dt.seconds % 3600) // 60) / tmp['COUNT'])).astype('int')\n",
    "transactions_df['mean_time_to_tran_min'] = transactions_df['USER_ID'].map(tmp[['USER_ID', 'mean_time_to_tran_min']].set_index('USER_ID').squeeze())\n",
    "transactions = generate_date_features(transactions_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "txn = pd.melt(transactions_df, id_vars=['USER_ID'], value_vars=['TYPE', 'STATE', 'COUNTRY', 'CURRENCY', 'time_bin'])\n",
    "txg = pd.melt(transactions, id_vars=['USER_ID'], value_vars=['TYPE', 'STATE', 'COUNTRY', 'CURRENCY', 'time_bin'])\n",
    "txg['TOKEN'] = txg['variable'].astype(str) + \"_\" + txg[\"value\"].astype(str)\n",
    "txg = txg[['USER_ID', 'TOKEN']].groupby(['USER_ID', 'TOKEN']).size().reset_index()\n",
    "txg.columns = ['USER_ID', 'TOKEN', 'TF']\n",
    "usg = txg[['USER_ID', 'TOKEN']].groupby(['USER_ID']).size().reset_index()\n",
    "usg.columns = ['USER_ID', 'IDF']\n",
    "txg = txg.merge(usg, on='USER_ID')\n",
    "txg['TF_IDF'] = txg['TF'] / txg['IDF']\n",
    "txg = txg[['USER_ID', 'TOKEN', 'TF_IDF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = list(txg.itertuples(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "g= nx.Graph()\n",
    "g.add_nodes_from(txg['USER_ID'], bipartite=0)\n",
    "g.add_nodes_from(txg['TOKEN'], bipartite=1)\n",
    "g.add_weighted_edges_from(edge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1068361, 27)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200447"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_bipartite(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_connected(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_nodes, top_nodes = bipartite.sets(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "biadjacency_matrix() missing 1 required positional argument: 'row_order'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m biadjacency \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39;49malgorithms\u001b[39m.\u001b[39;49mbipartite\u001b[39m.\u001b[39;49mmatrix\u001b[39m.\u001b[39;49mbiadjacency_matrix(g)\n\u001b[1;32m      2\u001b[0m \u001b[39m# names_row = graph.names_row\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# names_col = graph.names_col\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[39m# louvain = Louvain(resolution=1.7, modularity='newman')\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: biadjacency_matrix() missing 1 required positional argument: 'row_order'"
     ]
    }
   ],
   "source": [
    "biadjacency = nx.algorithms.bipartite.matrix.biadjacency_matrix(g)\n",
    "# names_row = graph.names_row\n",
    "# names_col = graph.names_col\n",
    "# louvain = Louvain(resolution=1.7, modularity='newman')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xente-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
