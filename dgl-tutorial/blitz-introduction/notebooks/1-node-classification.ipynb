{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Node Classification with DGL\n",
    "\n",
    "Source: https://docs.dgl.ai/tutorials/blitz/1_introduction.html#sphx-glr-tutorials-blitz-1-introduction-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DGLBACKEND'] = 'pytorch'\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import dgl\n",
    "import dgl.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "# Data loading \n",
    "data = dgl.data.CoraGraphDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories: 7\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of categories: {data.num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(\"cora_v2\", num_graphs=1, save_path=/home/dloader-ubuntu/.dgl/cora_v2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=2708, num_edges=10556,\n",
       "      ndata_schemes={'feat': Scheme(shape=(1433,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'train_mask': Scheme(shape=(), dtype=torch.bool)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features: {'feat': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'label': tensor([3, 4, 4,  ..., 3, 3, 3]), 'test_mask': tensor([False, False, False,  ...,  True,  True,  True]), 'val_mask': tensor([False, False, False,  ..., False, False, False]), 'train_mask': tensor([ True,  True,  True,  ..., False, False, False])}. Edge features: {}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Node features: {g.ndata}. Edge features: {g.edata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "        \n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g,h)\n",
    "        return h\n",
    "    \n",
    "# Create the GCN model \n",
    "model = GCN(g.ndata['feat'].shape[1], 16, data.num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=2708, num_edges=10556,\n",
       "      ndata_schemes={'feat': Scheme(shape=(1433,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'train_mask': Scheme(shape=(), dtype=torch.bool)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCN Training\n",
    "def train(g, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "    \n",
    "    # Get variables from the graph\n",
    "    features = g.ndata['feat']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    val_mask = g.ndata['val_mask']\n",
    "    test_mask = g.ndata['test_mask']\n",
    "    \n",
    "    for e in range(100):\n",
    "        # Forward pass\n",
    "        logits = model(g, features)\n",
    "        \n",
    "        # Compute the prediction\n",
    "        pred = logits.argmax(1)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "        \n",
    "        # Compute the accuracy on training/validation/test set\n",
    "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
    "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
    "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
    "        \n",
    "        # Save the best validation acc and the test accuracy\n",
    "        # print(f\"Validation accuracy: {val_acc:.4f} Test accuracy: {test_acc:.4f}\")\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if e % 5 == 0:\n",
    "            print(f\"In epoch {e}, loss: {loss:.4f}, validation accuracy (best): {val_acc:.4f} ({best_val_acc:.4f}), test accuracy (best): {test_acc:.4f} ({best_test_acc:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 1.9458, validation accuracy (best): 0.1300 (0.1300), test accuracy (best): 0.1400 (0.1400)\n",
      "In epoch 5, loss: 1.8856, validation accuracy (best): 0.5740 (0.5940), test accuracy (best): 0.5880 (0.6040)\n",
      "In epoch 10, loss: 1.7987, validation accuracy (best): 0.6300 (0.6300), test accuracy (best): 0.6400 (0.6490)\n",
      "In epoch 15, loss: 1.6873, validation accuracy (best): 0.6300 (0.6300), test accuracy (best): 0.6370 (0.6490)\n",
      "In epoch 20, loss: 1.5532, validation accuracy (best): 0.6660 (0.6660), test accuracy (best): 0.6700 (0.6700)\n",
      "In epoch 25, loss: 1.4000, validation accuracy (best): 0.6880 (0.6880), test accuracy (best): 0.6940 (0.6940)\n",
      "In epoch 30, loss: 1.2345, validation accuracy (best): 0.7140 (0.7140), test accuracy (best): 0.7070 (0.7070)\n",
      "In epoch 35, loss: 1.0653, validation accuracy (best): 0.7240 (0.7240), test accuracy (best): 0.7210 (0.7160)\n",
      "In epoch 40, loss: 0.9011, validation accuracy (best): 0.7340 (0.7340), test accuracy (best): 0.7330 (0.7330)\n",
      "In epoch 45, loss: 0.7496, validation accuracy (best): 0.7360 (0.7400), test accuracy (best): 0.7390 (0.7390)\n",
      "In epoch 50, loss: 0.6157, validation accuracy (best): 0.7440 (0.7440), test accuracy (best): 0.7460 (0.7460)\n",
      "In epoch 55, loss: 0.5015, validation accuracy (best): 0.7540 (0.7540), test accuracy (best): 0.7540 (0.7540)\n",
      "In epoch 60, loss: 0.4070, validation accuracy (best): 0.7600 (0.7600), test accuracy (best): 0.7580 (0.7580)\n",
      "In epoch 65, loss: 0.3304, validation accuracy (best): 0.7660 (0.7660), test accuracy (best): 0.7690 (0.7690)\n",
      "In epoch 70, loss: 0.2692, validation accuracy (best): 0.7640 (0.7680), test accuracy (best): 0.7680 (0.7700)\n",
      "In epoch 75, loss: 0.2207, validation accuracy (best): 0.7680 (0.7680), test accuracy (best): 0.7680 (0.7700)\n",
      "In epoch 80, loss: 0.1822, validation accuracy (best): 0.7700 (0.7700), test accuracy (best): 0.7680 (0.7700)\n",
      "In epoch 85, loss: 0.1519, validation accuracy (best): 0.7680 (0.7700), test accuracy (best): 0.7670 (0.7700)\n",
      "In epoch 90, loss: 0.1279, validation accuracy (best): 0.7620 (0.7700), test accuracy (best): 0.7660 (0.7700)\n",
      "In epoch 95, loss: 0.1088, validation accuracy (best): 0.7620 (0.7700), test accuracy (best): 0.7610 (0.7700)\n"
     ]
    }
   ],
   "source": [
    "model = GCN(g.ndata['feat'].shape[1], 16, data.num_classes)\n",
    "train(g, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on The GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dloader-ubuntu/miniconda3/envs/dgl-tutorial-env/lib/python3.11/site-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 1.9453, validation accuracy (best): 0.1220 (0.1220), test accuracy (best): 0.1460 (0.1460)\n",
      "In epoch 5, loss: 1.8909, validation accuracy (best): 0.5020 (0.5020), test accuracy (best): 0.5080 (0.5080)\n",
      "In epoch 10, loss: 1.8091, validation accuracy (best): 0.5740 (0.5740), test accuracy (best): 0.6130 (0.6130)\n",
      "In epoch 15, loss: 1.7048, validation accuracy (best): 0.5960 (0.5960), test accuracy (best): 0.6370 (0.6370)\n",
      "In epoch 20, loss: 1.5788, validation accuracy (best): 0.6380 (0.6380), test accuracy (best): 0.6820 (0.6820)\n",
      "In epoch 25, loss: 1.4340, validation accuracy (best): 0.6660 (0.6660), test accuracy (best): 0.7140 (0.7140)\n",
      "In epoch 30, loss: 1.2746, validation accuracy (best): 0.6880 (0.6880), test accuracy (best): 0.7340 (0.7340)\n",
      "In epoch 35, loss: 1.1075, validation accuracy (best): 0.6940 (0.6940), test accuracy (best): 0.7470 (0.7390)\n",
      "In epoch 40, loss: 0.9414, validation accuracy (best): 0.7120 (0.7120), test accuracy (best): 0.7510 (0.7510)\n",
      "In epoch 45, loss: 0.7845, validation accuracy (best): 0.7260 (0.7260), test accuracy (best): 0.7670 (0.7670)\n",
      "In epoch 50, loss: 0.6437, validation accuracy (best): 0.7340 (0.7340), test accuracy (best): 0.7700 (0.7710)\n",
      "In epoch 55, loss: 0.5225, validation accuracy (best): 0.7480 (0.7480), test accuracy (best): 0.7730 (0.7730)\n",
      "In epoch 60, loss: 0.4218, validation accuracy (best): 0.7600 (0.7600), test accuracy (best): 0.7780 (0.7780)\n",
      "In epoch 65, loss: 0.3403, validation accuracy (best): 0.7600 (0.7620), test accuracy (best): 0.7770 (0.7790)\n",
      "In epoch 70, loss: 0.2755, validation accuracy (best): 0.7580 (0.7620), test accuracy (best): 0.7760 (0.7790)\n",
      "In epoch 75, loss: 0.2245, validation accuracy (best): 0.7660 (0.7660), test accuracy (best): 0.7760 (0.7780)\n",
      "In epoch 80, loss: 0.1844, validation accuracy (best): 0.7660 (0.7660), test accuracy (best): 0.7750 (0.7780)\n",
      "In epoch 85, loss: 0.1530, validation accuracy (best): 0.7660 (0.7660), test accuracy (best): 0.7750 (0.7780)\n",
      "In epoch 90, loss: 0.1282, validation accuracy (best): 0.7620 (0.7660), test accuracy (best): 0.7750 (0.7780)\n",
      "In epoch 95, loss: 0.1086, validation accuracy (best): 0.7700 (0.7700), test accuracy (best): 0.7750 (0.7750)\n"
     ]
    }
   ],
   "source": [
    "# Move the graph to the GPU\n",
    "g = g.to('cuda:0')\n",
    "model = GCN(g.ndata['feat'].shape[1], 16, data.num_classes).to('cuda:0')\n",
    "train(g, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xente-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
